@article{Moss2017,
abstract = {Background: Charted vital signs and laboratory results represent intermittent samples of a patient's dynamic physiologic state and have been used to calculate early warning scores to identify patients at risk of clinical deterioration. We hypothesized that the addition of cardiorespiratory dynamics measured from continuous electrocardiography (ECG) monitoring to intermittently sampled data improves the predictive validity of models trained to detect clinical deterioration prior to intensive care unit (ICU) transfer or unanticipated death. Methods and findings: We analyzed 63 patient-years of ECG data from 8,105 acute care patient admissions at a tertiary care academic medical center. We developed models to predict deterioration resulting in ICU transfer or unanticipated death within the next 24 hours using either vital signs, laboratory results, or cardiorespiratory dynamics from continuous ECG monitoring and also evaluated models using all available data sources. We calculated the predictive validity (C-statistic), the net reclassification improvement, and the probability of achieving the difference in likelihood ratio $\chi$2 for the additional degrees of freedom. The primary outcome occurred 755 times in 586 admissions (7%). We analyzed 395 clinical deteriorations with continuous ECG data in the 24 hours prior to an event. Using only continuous ECG measures resulted in a C-statistic of 0.65, similar to models using only laboratory results and vital signs (0.63 and 0.69 respectively). Addition of continuous ECG measures to models using conventional measurements improved the C-statistic by 0.01 and 0.07; a model integrating all data sources had a C-statistic of 0.73 with categorical net reclassification improvement of 0.09 for a change of 1 decile in risk. The difference in likelihood ratio $\chi$2 between integrated models with and without cardiorespiratory dynamics was 2158 (p value: <0.001). Conclusions: Cardiorespiratory dynamics from continuous ECG monitoring detect clinical deterioration in acute care patients and improve performance of conventional models that use only laboratory results and vital signs.},
author = {Moss, Travis J. and Clark, Matthew T. and Calland, James Forrest and Enfield, Kyle B. and Voss, John D. and Lake, Douglas E. and Moorman, J. Randall},
doi = {10.1371/journal.pone.0181448},
file = {:home/nghia/PR_LAB/RRS/ref/pone.0181448.pdf:pdf},
isbn = {1111111111},
issn = {19326203},
journal = {PLoS ONE},
number = {8},
pages = {1--16},
pmid = {28771487},
title = {{Cardiorespiratory dynamics measured from continuous ECG monitoring improves detection of deterioration in acute care patients: A retrospective cohort study}},
volume = {12},
year = {2017}
}

@article{Kwon2018,
abstract = {Background—In-hospital cardiac arrest is a major burden to public health, which affects patient safety. Although traditional trackand- trigger systems are used to predict cardiac arrest early, they have limitations, with low sensitivity and high false-alarm rates. We propose a deep learning–based early warning system that shows higher performance than the existing track-and-trigger systems. Methods and Results—This retrospective cohort study reviewed patients who were admitted to 2 hospitals from June 2010 to July 2017. A total of 52 131 patients were included. Specifically, a recurrent neural network was trained using data from June 2010 to January 2017. The result was tested using the data from February to July 2017. The primary outcome was cardiac arrest, and the secondary outcome was death without attempted resuscitation. As comparative measures, we used the area under the receiver operating characteristic curve (AUROC), the area under the precision–recall curve (AUPRC), and the net reclassification index. Furthermore, we evaluated sensitivity while varying the number of alarms. The deep learning–based early warning system (AUROC: 0.850; AUPRC: 0.044) significantly outperformed a modified early warning score (AUROC: 0.603; AUPRC: 0.003), a random forest algorithm (AUROC: 0.780; AUPRC: 0.014), and logistic regression (AUROC: 0.613; AUPRC: 0.007). Furthermore, the deep learning– based early warning system reduced the number of alarms by 82.2%, 13.5%, and 42.1% compared with the modified early warning system, random forest, and logistic regression, respectively, at the same sensitivity. Conclusions—An algorithm based on deep learning had high sensitivity and a low false-alarm rate for detection of patients with cardiac arrest in the multicenter study.},
author = {Kwon, Joon Myoung and Lee, Youngnam and Lee, Yeha and Lee, Seungwoo and Park, Jinsik},
doi = {10.1161/JAHA.118.008678},
file = {:home/nghia/PR_LAB/RRS/ref/JAH3-7-e008678.pdf:pdf},
issn = {20479980},
journal = {Journal of the American Heart Association},
keywords = {Artificial intelligence,Cardiac arrest,Deep learning,Machine learning,Rapid response system,Resuscitation},
number = {13},
pages = {1--11},
pmid = {29945914},
title = {{An algorithm based on deep learning for predicting in-hospital cardiac arrest}},
volume = {7},
year = {2018}
}

@article{Shamout2020,
abstract = {Assessment of physiological instability preceding adverse events on hospital wards has been previously investigated through clinical early warning score systems. Early warning scores are simple to use yet they consider data as independent and identically distributed random variables. Deep learning applications are able to learn from sequential data, however they lack interpretability and are thus difficult to deploy in clinical settings. We propose the 'Deep Early Warning System' (DEWS), an interpretable end-to-end deep learning model that interpolates temporal data and predicts the probability of an adverse event, defined as the composite outcome of cardiac arrest, mortality or unplanned ICU admission. The model was developed and validated using routinely collected vital signs of patients admitted to the the Oxford University Hospitals between 21st March 2014 and 31st March 2018. We extracted 45 314 vital-sign measurements as a balanced training set and 359 481 vital-sign measurements as an imbalanced testing set to mimic a real-life setting of emergency admissions. DEWS achieved superior accuracy than the state-of-the-art that is currently implemented in clinical settings, the National Early Warning Score, in terms of the overall area under the receiver operating characteristic curve (AUROC) (0.880 vs. 0.866) and when evaluated independently for each of the three outcomes. Our attention-based architecture was able to recognize 'historical' trends in the data that are most correlated with the predicted probability. With high sensitivity, improved clinical utility and increased interpretability, our model can be easily deployed in clinical settings to supplement existing EWS systems.},
author = {Shamout, Farah E. and Zhu, Tingting and Sharma, Pulkit and Watkinson, Peter J. and Clifton, David A.},
doi = {10.1109/JBHI.2019.2937803},
file = {:home/nghia/PR_LAB/RRS/Deep Interpretable Early Warning System for theDetection of Clinical Deterioration.pdf:pdf},
issn = {21682208},
journal = {IEEE Journal of Biomedical and Health Informatics},
keywords = {Early warning system,data interpolation,deep learning,supervised learning,time-series data},
number = {2},
pages = {437--446},
pmid = {31545746},
publisher = {IEEE},
title = {{Deep Interpretable Early Warning System for the Detection of Clinical Deterioration}},
volume = {24},
year = {2020}
}

@article{Wang2019,
abstract = {Existing works about fashion outfit compatibility focus on predicting the overall compatibility of a set of fashion items with their information from different modalities. However, there are few works explore how to explain the prediction, which limits the persuasiveness and effectiveness of the model. In this work, we propose an approach to not only predict but also diagnose the outfit compatibility. We introduce an end-to-end framework for this goal, which features for: (1) The overall compatibility is learned from all type-specified pairwise similarities between items, and the backpropagation gradients are used to diagnose the incompatible factors. (2) We leverage the hierarchy of CNN and compare the features at different layers to take into account the compatibilities of different aspects from the low level (such as color, texture) to the high level (such as style). To support the proposed method, we build a new type-specified outfit dataset named Polyvore-T based on Polyvore dataset. We compare our method with the prior state-of-the-art in two tasks: outfit compatibility prediction and fill-in-the-blank. Experiments show that our approach has advantages in both prediction performance and diagnosis ability.},
archivePrefix = {arXiv},
arxivId = {1907.11496},
author = {Wang, Xin and Wu, Bo and Zhong, Yueqi},
doi = {10.1145/3343031.3350909},
eprint = {1907.11496},
file = {:home/nghia/CNU-SEM4/AI_ConV/ref/1907.11496.pdf:pdf},
isbn = {9781450368896},
journal = {MM 2019 - Proceedings of the 27th ACM International Conference on Multimedia},
keywords = {Deep Learning,Fashion Recommendation,Outfit Compatibility},
pages = {329--337},
title = {{Outfit compatibility prediction and diagnosis with multi-layered comparison network}},
year = {2019}
}
@article{Li2017,
abstract = {Composing fashion outfits involves deep under-standing of fashion standards while incorporating creativity for choosing multiple fashion items (e.g., jewelry, bag, pants, dress). In fashion websites, popular or high-quality fashion outfits are usually designed by fashion experts and followed by large audiences. In this paper, we propose a machine learning system to compose fashion outfits automatically. The core of the proposed automatic composition system is to score fashion outfit candidates based on the appearances and metadata. We propose to leverage outfit popularity on fashion-oriented websites to supervise the scoring component. The scoring component is a multimodal multiinstance deep learning system that evaluates instance aesthetics and set compatibility simultaneously. In order to train and evaluate the proposed composition system, we have collected a large-scale fashion outfit dataset with 195K outfits and 368K fashion items from Polyvore. Although the fashion outfit scoring and composition is rather challenging, we have achieved an AUC of 85% for the scoring component, and an accuracy of 77% for a constrained composition task.},
archivePrefix = {arXiv},
arxivId = {1608.03016},
author = {Li, Yuncheng and Cao, Liangliang and Zhu, Jiang and Luo, Jiebo},
doi = {10.1109/TMM.2017.2690144},
eprint = {1608.03016},
file = {:home/nghia/CNU-SEM4/AI_ConV/ref/1608.03016.pdf:pdf},
issn = {15209210},
journal = {IEEE Transactions on Multimedia},
keywords = {Big data applications,multilayer neural network,multimedia computing},
number = {8},
pages = {1946--1955},
title = {{Mining fashion outfit composition using an end-to-end deep learning approach on set data}},
volume = {19},
year = {2017}
}

@article{Tangseng2018,
abstract = {We consider grading a fashion outfit for recommendation, where we assume that users have a closet of items and we aim at producing a score for an arbitrary combination of items in the closet. The challenge in outfit grading is that the input to the system is a bag of item pictures that are unordered and vary in size. We build a deep neural network-based system that can take variable-length items and predict a score. We collect a large number of outfits from a popular fashion sharing website, Polyvore, and evaluate the performance of our grading system. We compare our model with a random-choice baseline, both on the traditional classification evaluation and on people's judgment using a crowdsourcing platform. With over 84% in classification accuracy and 91% matching ratio to human annotators, our model can reliably grade the quality of an outfit. We also build an outfit recommender on top of our grader to demonstrate the practical application of our model for a personal closet assistant.},
archivePrefix = {arXiv},
arxivId = {1804.09979},
author = {Tangseng, Pongsate and Yamaguchi, Kota and Okatani, Takayuki},
doi = {10.1109/WACV.2018.00036},
eprint = {1804.09979},
file = {:home/nghia/CNU-SEM4/AI_ConV/ref/1804.09979.pdf:pdf},
isbn = {9781538648865},
journal = {Proceedings - 2018 IEEE Winter Conference on Applications of Computer Vision, WACV 2018},
pages = {269--277},
title = {{Recommending Outfits from Personal Closet}},
volume = {2018-January},
year = {2018}
}

@article{Davis,
archivePrefix = {arXiv},
arxivId = {arXiv:1707.05691v1},
author = {Davis, Larry S},
doi = {10.1145/3123266.3123394},
eprint = {arXiv:1707.05691v1},
file = {:home/nghia/CNU-SEM4/AI_ConV/ref/1707.05691.pdf:pdf},
isbn = {9781450349062},
keywords = {bidirectional lstm,compatibility learning,deep learning,fashion recommendation,figure 1,tasks of fashion recommenda-,visual,we focus on three},
number = {1},
title = {{Learning Fashion Compatibility with Bidirectional LSTMs}}
}

@article{Wang2018,
abstract = {Both convolutional and recurrent operations are building blocks that process one local neighborhood at a time. In this paper, we present non-local operations as a generic family of building blocks for capturing long-range dependencies. Inspired by the classical non-local means method [4] in computer vision, our non-local operation computes the response at a position as a weighted sum of the features at all positions. This building block can be plugged into many computer vision architectures. On the task of video classification, even without any bells and whistles, our nonlocal models can compete or outperform current competition winners on both Kinetics and Charades datasets. In static image recognition, our non-local models improve object detection/segmentation and pose estimation on the COCO suite of tasks. Code will be made available.},
archivePrefix = {arXiv},
arxivId = {1711.07971},
author = {Wang, Xiaolong and Girshick, Ross and Gupta, Abhinav and He, Kaiming},
doi = {10.1109/CVPR.2018.00813},
eprint = {1711.07971},
file = {:home/nghia/CNU-SEM4/AI_ConV/ref/1711.07971.pdf:pdf},
isbn = {9781538664209},
issn = {10636919},
journal = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
pages = {7794--7803},
title = {{Non-local Neural Networks}},
year = {2018}
}

@article{Vasileva2018,
abstract = {Outfits in online fashion data are composed of items of many different types (e.g. top, bottom, shoes) that share some stylistic relationship with one another. A representation for building outfits requires a method that can learn both notions of similarity (for example, when two tops are interchangeable) and compatibility (items of possibly different type that can go together in an outfit). This paper presents an approach to learning an image embedding that respects item type, and jointly learns notions of item similarity and compatibility in an end-to-end model. To evaluate the learned representation, we crawled 68,306 outfits created by users on the Polyvore website. Our approach obtains 3–5% improvement over the state-of-the-art on outfit compatibility prediction and fill-in-the-blank tasks using our dataset, as well as an established smaller dataset, while supporting a variety of useful queries (Code and data: https://github.com/mvasil/fashion-compatibility ).},
archivePrefix = {arXiv},
arxivId = {1803.09196},
author = {Vasileva, Mariya I. and Plummer, Bryan A. and Dusad, Krishna and Rajpal, Shreya and Kumar, Ranjitha and Forsyth, David},
doi = {10.1007/978-3-030-01270-0_24},
eprint = {1803.09196},
file = {:home/nghia/CNU-SEM4/AI_ConV/ref/1803.09196.pdf:pdf},
isbn = {9783030012694},
issn = {16113349},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {Appearance representations,Embedding methods,Fashion},
pages = {405--421},
title = {{Learning Type-Aware Embeddings for Fashion Compatibility}},
volume = {11220 LNCS},
year = {2018}
}

